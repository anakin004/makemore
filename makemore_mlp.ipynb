{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxNimLjOXCChPfCdPn6mAD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5ZuaZUp5oJh8"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import torch\n",
        "import os\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset() -> str:\n",
        "    path = kagglehub.dataset_download(\"rishitjakharia/names-txt\")\n",
        "    return path # for easier access later"
      ],
      "metadata": {
        "id": "g44jFQs2qCGl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = download_dataset() + \"/names.txt\""
      ],
      "metadata": {
        "id": "MA9H16s-qPXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ae9645-9e48-4808-f48f-9aa7dd6f1e65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rishitjakharia/names-txt?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113k/113k [00:00<00:00, 393kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(dataset_path, 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "VYqGvxdiqWwr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_int_char_maps() -> tuple[dict, dict]:\n",
        "  chars = sorted(list(set(''.join(words))))\n",
        "  ctoi = {c: i + 1 for i, c in enumerate(chars)}\n",
        "  ctoi['.'] = 0\n",
        "  itoc = {i: c for c, i in ctoi.items()}\n",
        "  return ctoi, itoc"
      ],
      "metadata": {
        "id": "K2-SWXb-qnq7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctoi, itoc = make_int_char_maps()"
      ],
      "metadata": {
        "id": "RdXYrtwBq5sT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(itoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niQbCUjPrAuD",
        "outputId": "ab3040d6-2613-4a54-bc07-82deeac7ff56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ctoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t-Rs9ExvDw2",
        "outputId": "d5eb4ef5-5063-4282-c393-0619be99e371"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset() -> tuple[torch.tensor, torch.tensor]:\n",
        "\n",
        "  block_size = 3 # context length -> how many chars does it take to predict the next\n",
        "  inp, target = [], []\n",
        "  for w in words[:5]:\n",
        "\n",
        "    print(w)\n",
        "    context = [0] * block_size\n",
        "\n",
        "    for ch in w + '.':\n",
        "      ix = ctoi[ch]\n",
        "      inp.append(context)\n",
        "      target.append(ix)\n",
        "      print(''.join(itoc[i] for i in context), '--->', ch)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  inp = torch.tensor(inp)\n",
        "  target = torch.tensor(target)\n",
        "  return inp, target"
      ],
      "metadata": {
        "id": "jJqoPknQvJ2N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp, target = build_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1sfcaPUvugF",
        "outputId": "2fb6ca38-88ca-4ff0-f8da-381e7ff7738e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "olivia\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "ava\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "isabella\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "sophia\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp.shape, target.shape, inp.dtype, target.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0H48XDAw6pF",
        "outputId": "d324f2f5-3114-45f9-ddb2-133b76745de5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]), torch.int64, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27, 2) # 27 characters mapping to a 2d vector embedding`"
      ],
      "metadata": {
        "id": "4kGCz2qwzO7h"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L9q2jaQyDo7",
        "outputId": "9888fa22-4d5f-4f6f-eb36-53a7b38b6438"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2407, -0.5596])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(F.one_hot(torch.tensor(5), num_classes=27).float() @ C) # one hot allows us to pluck out a desired row\n",
        "                                                         # however, notice its the same as indexing, so this wont be used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkqeYAHGxUOj",
        "outputId": "a5cb93c0-d975-48dc-fb46-173615b137d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2407, -0.5596])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inp contains contexts, defined in build dataset above\n",
        "each context contains index mappings from ctoi.\n",
        "these allow us to access embeddings in C.\n",
        "we can index into C efficienty with the help of PyTorch"
      ],
      "metadata": {
        "id": "sYTSkiT82Vgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[inp].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FberbX73zJ3a",
        "outputId": "563b4172-b41a-4ad2-969a-1710f619e47d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[inp]"
      ],
      "metadata": {
        "id": "XWXADcbw2_Fj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6, 100)) # this is our hiddem layer, recieving 6 inputs, since each input has three characters, each having two elements\n",
        "B1 = torch.randn(100) # 100 biases for each weight"
      ],
      "metadata": {
        "id": "tgpQBgFp2En3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.tanh(emb.view(-1, 6) @ W1 + B1)"
      ],
      "metadata": {
        "id": "wV_f27LP0isl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMo7jzfs3Z4I",
        "outputId": "6f67ae5d-7ca3-4bef-c6a3-46473e819829"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2316,  0.9908,  0.5361,  ...,  0.9283,  0.9778,  0.6312],\n",
              "        [-0.8250,  0.9907,  0.8158,  ...,  0.6804,  0.9887, -0.0046],\n",
              "        [-0.2868,  0.9943,  0.5957,  ...,  0.9743,  0.9805,  0.6827],\n",
              "        ...,\n",
              "        [ 0.9960,  0.9889, -0.9173,  ...,  0.9727,  0.9960,  0.8921],\n",
              "        [ 0.9994,  0.9344,  0.8807,  ...,  0.9076,  0.9999,  0.9985],\n",
              "        [ 0.9965,  0.8027,  0.6306,  ...,  0.9800,  0.9919,  0.9441]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(100, 27)\n",
        "B2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "JSh1u3lk3ayF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + B2"
      ],
      "metadata": {
        "id": "iK8nE4re3kiB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "Ny_-MBnc3nNI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = counts / counts.sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "I9GktJTP3qXY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs[torch.arange(32), target] # the probabilties for our target characters for each input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-S4hsQh3xov",
        "outputId": "fff33310-c586-4d25-e1d5-7f20bd8887c5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.6508e-03, 8.1141e-02, 2.0798e-01, 4.0672e-03, 8.7438e-04, 1.0611e-02,\n",
              "        5.4549e-03, 4.2308e-03, 1.5276e-04, 4.7371e-03, 2.8948e-05, 1.4128e-02,\n",
              "        1.9483e-03, 1.5560e-03, 1.5678e-03, 3.2267e-03, 1.8552e-02, 2.1501e-03,\n",
              "        1.1183e-04, 3.4877e-02, 7.6664e-04, 6.5152e-04, 4.5874e-03, 3.5471e-03,\n",
              "        5.8964e-05, 2.5159e-03, 4.2476e-03, 6.8626e-04, 2.3269e-04, 3.0489e-05,\n",
              "        5.2686e-02, 1.4095e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -probs[torch.arange(32), target].log().mean()"
      ],
      "metadata": {
        "id": "KTQFEIrx8X5c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbUXlXdv8bs7",
        "outputId": "7e5f24b0-1ff6-4be9-8e2d-59d8acfd683e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.1197509765625"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now altogether"
      ],
      "metadata": {
        "id": "s5bPj1uA9H0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6, 100))\n",
        "B1 = torch.randn(100)\n",
        "W2 = torch.randn(100, 27)\n",
        "B2 = torch.randn(27)\n",
        "params = [C, W1, B1, W2, B2]"
      ],
      "metadata": {
        "id": "nREQ1NCc9KRm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in params ) # number of parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F3OeE-E9qJR",
        "outputId": "d5fbfc89-4bdd-45e4-f23f-8eaf9a6ad23c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[inp]\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + B1)\n",
        "logits = h @ W2 + B2\n",
        "loss = F.cross_entropy(logits, target)"
      ],
      "metadata": {
        "id": "hYCvnMC299cw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss # this loss is different from above because we initialize new random weights and biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAdWXfJM-oPU",
        "outputId": "05fd1932-30f6-4be0-b4c2-44e26fd23be6"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.5559)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "F.cross_entropy on logits and target does this calculation, giving the same loss when -prob[torch.arange(32), target].log().mean() is calculated, but much quicker"
      ],
      "metadata": {
        "id": "Q6VOAwnAJyvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit = torch.tensor([-5, 0, 3, 5]) + 6\n",
        "count = logit.exp()\n",
        "prob = count / count.sum()\n",
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwFWs5xvHQZW",
        "outputId": "7617dcfb-d3cc-42cd-bf73-836601b78511"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.9751e-05, 5.8995e-03, 1.1849e-01, 8.7557e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any constant we add to logits will still result in the same prob ...\n",
        "Let the logits be:\n",
        "$$\n",
        "\\text{logit} = \\begin{bmatrix} -5 \\\\ 0 \\\\ 3 \\\\ 5 \\end{bmatrix} + 6 = \\begin{bmatrix} 1 \\\\ 6 \\\\ 9 \\\\ 11 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Exponentiated values:\n",
        "$$\n",
        "\\text{count} = \\exp(\\text{logit}) = \\begin{bmatrix} e^1 \\\\ e^6 \\\\ e^9 \\\\ e^{11} \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "This Also Equals\n",
        "$$\n",
        "\\exp(\\text{logit}) = e^6 ⋅ \\begin{bmatrix} e^{-5} \\\\ e^0 \\\\ e^3 \\\\ e^{5} \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Normalized probabilities:\n",
        "$$\n",
        "\\text{prob} = \\frac{\\text{count}}{\\sum \\text{count}} = \\frac{e^6 \\cdot \\begin{bmatrix} e^{-5} \\\\ e^0 \\\\ e^3 \\\\ e^5 \\end{bmatrix}}{e^6 \\cdot (e^{-5} + e^0 + e^3 + e^5)}\n",
        "$$\n",
        "\n",
        "Further:\n",
        "$$\n",
        "\\text{prob} = \\frac{\\text{count}}{\\sum \\text{count}} = \\frac{\\begin{bmatrix} e^{-5} \\\\ e^0 \\\\ e^3 \\\\ e^5 \\end{bmatrix}}{e^{-5} + e^0 + e^3 + e^5} \\text{, Which is simply the normalization of our original tensor}\n",
        "$$\n",
        "\n",
        "Adding a constant to our logits does not change the probability tensor, given we don't go out of bounds when calculating exp. Negative numbers will be useful here, since if we have a overflowing number already in our logits, then it can overflow in counts, but if we offset by -max(logits) then we can can ensure no overflow"
      ],
      "metadata": {
        "id": "_YW6aJ4lHxN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# overflow example\n",
        "logit = torch.tensor([-5, 0, 3, 100])\n",
        "count = logit.exp()\n",
        "prob = count / count.sum()\n",
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9PTOBJdK3Do",
        "outputId": "075b05e1-ffc2-4944-d4cd-2e25ec0b9f83"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., nan])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixing overflow\n",
        "logit = torch.tensor([-5, 0, 3, 100]) - logit.max()\n",
        "count = logit.exp()\n",
        "prob = count / count.sum()\n",
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FaWIdXPK7QW",
        "outputId": "54a1af06-dd56-4a1b-d2a4-dc6000d9aabe"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 3.7835e-44, 7.4689e-43, 1.0000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# further showing we can add any constant as long as we dont overflow\n",
        "logit = torch.tensor([-5, 0, 3, 100]) - logit.max() + 1\n",
        "count = logit.exp()\n",
        "prob = count / count.sum()\n",
        "prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeER-lflLrG4",
        "outputId": "adb91bc6-a86d-4af6-a29f-7bc89bb5c412"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000e+00, 3.7835e-44, 7.4689e-43, 1.0000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    }
  ]
}